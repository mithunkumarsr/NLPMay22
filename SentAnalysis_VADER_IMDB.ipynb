{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentAnalysis_VADER_IMDB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbCjKglO/HXl+oZqsreaAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/NLPMay22/blob/main/SentAnalysis_VADER_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGGPrMVz6-A4"
      },
      "source": [
        "https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-rule-based-vader-and-nltk-72067970fb71\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh18aDQT668f",
        "outputId": "0f7f78b4-9790-4f12-f734-574df31a80fc"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(train_data_raw, train_labels), (test_data_raw, test_labels) = tf.keras.datasets.imdb.load_data(index_from=3)\n",
        "words2idx = tf.keras.datasets.imdb.get_word_index()\n",
        "idx2words = {idx:word for word, idx in words2idx.items()}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an6R_mpo7Mb4",
        "outputId": "80063c9e-dff7-43e0-e1f0-9726e2f7d7e9"
      },
      "source": [
        "# Let's see an example\n",
        "train_ex = [idx2words[x-3] for x in train_data_raw[0][1:]] # We use x-3 because when we load the data above, we used index_form=3\n",
        "train_ex = ' '.join(train_ex)\n",
        "print(train_ex)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF_YfPRv7UKi",
        "outputId": "b0e6b599-9ba1-4bf4-9659-e9df4f42a97b"
      },
      "source": [
        "imdb_reviews = []\n",
        "for review, label in zip(train_data_raw, train_labels):\n",
        "  try:\n",
        "    tokens = [idx2words[x-3] for x in review[1:]]\n",
        "    text = ' '.join(tokens)\n",
        "    imdb_reviews.append([text, label])\n",
        "  except: # There is a distorted observation. For that, we need to handle the error\n",
        "    print('Small index number')\n",
        "    pass"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small index number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OW_T-az7YUJ",
        "outputId": "ae826a11-a213-464e-df55-b0f1a76616a9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "imdb_df = pd.DataFrame(imdb_reviews,columns=['Text', 'Label'])\n",
        "print(imdb_df.info())\n",
        "print(imdb_df.head(10))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24999 entries, 0 to 24998\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Text    24999 non-null  object\n",
            " 1   Label   24999 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 390.7+ KB\n",
            "None\n",
            "                                                Text  Label\n",
            "0  this film was just brilliant casting location ...      1\n",
            "1  big hair big boobs bad music and a giant safet...      0\n",
            "2  this has to be one of the worst films of the 1...      0\n",
            "3  the scots excel at storytelling the traditiona...      1\n",
            "4  worst mistake of my life br br i picked this m...      0\n",
            "5  begins better than it ends funny that the russ...      0\n",
            "6  lavish production values and solid performance...      1\n",
            "7  the hamiltons tells the story of the four hami...      0\n",
            "8  just got out and cannot believe what a brillia...      1\n",
            "9  this movie has many problem associated with it...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yJ0bYpE7ndb",
        "outputId": "42f76c72-86a9-402a-be48-b4938fde8427"
      },
      "source": [
        "# Loading VADER Sentiment Intensity Analyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNz9JKbi7uz0",
        "outputId": "9386f15f-1c5c-478d-cfa0-904528d1292d"
      },
      "source": [
        "\n",
        "sentences = ['Hello, world. I am terrible']\n",
        "for sentence in sentences:\n",
        "  print(sentence)\n",
        "  ss = sia.polarity_scores(sentence)\n",
        "  for k in sorted(ss):\n",
        "    print('{0}: {1}, '.format(k, ss[k]), end='')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world. I am terrible\n",
            "compound: -0.4767, neg: 0.508, neu: 0.492, pos: 0.0, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4lj3TmZ7-Dy"
      },
      "source": [
        "# Shuffle data, Not really necessary, just for healthy practice\n",
        "imdb_slice = imdb_df.sample(frac=1.0).reset_index(drop=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNr2zvzS8GY0"
      },
      "source": [
        "\n",
        "# Create Prediction column based on Polarity Score\n",
        "imdb_slice['Prediction'] = imdb_slice['Text'].apply(lambda x: 1 if sia.polarity_scores(x)['compound'] >= 0 else -1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i68Brdez8Uiz"
      },
      "source": [
        "# Edit Label column 1 for Positive, -1 for Negative\n",
        "imdb_slice['Label'] = imdb_slice['Label'].apply(lambda x: -1 if x == 0 else 1)\n",
        "\n",
        "# Check if the Label column and Prediction column match for accuracy calculation\n",
        "imdb_slice['Accuracy'] = imdb_slice.apply(lambda x: 1 if x[1] == x[2] else 0, axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSClAKB98bjh"
      },
      "source": [
        "def conf_matrix(x):\n",
        "  if x[1] == 1 and x[2] == 1:\n",
        "    return 'TP'\n",
        "  elif x[1] == 1 and x[2] == -1:\n",
        "    return 'FN'\n",
        "  elif x[1] == -1 and x[2] == 1:\n",
        "    return 'FP'\n",
        "  elif x[1] == -1 and x[2] == -1:\n",
        "    return 'TN'\n",
        "  else:\n",
        "    return 0\n",
        "    \n",
        "imdb_slice['Conf_Matrix'] = imdb_slice.apply(lambda x: conf_matrix(x), axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "cvy9O5m08gVm",
        "outputId": "423342e5-9581-4129-94c1-782f787690de"
      },
      "source": [
        "imdb_slice.tail(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Text  Label  Prediction  \\\n",
              "24989  it has been said that deanna durbin invented t...      1           1   \n",
              "24990  meatball machine has got to be one of the most...     -1          -1   \n",
              "24991  this will be a different kind of review i've s...      1           1   \n",
              "24992  this is a refreshing enjoyable movie if you en...      1           1   \n",
              "24993  this movie is a must for all people that enjoy...      1           1   \n",
              "24994  okay this film probably deserves 7 out of 10 s...      1           1   \n",
              "24995  this is one of the most overlooked gems hollyw...      1           1   \n",
              "24996  not sure why this movie seems to have gotten s...     -1           1   \n",
              "24997  good lord whoever made this turkey needs to be...     -1           1   \n",
              "24998  skip mccoy richard widmark pick pockets candy'...      1           1   \n",
              "\n",
              "       Accuracy Conf_Matrix  \n",
              "24989         1          TP  \n",
              "24990         1          TN  \n",
              "24991         1          TP  \n",
              "24992         1          TP  \n",
              "24993         1          TP  \n",
              "24994         1          TP  \n",
              "24995         1          TP  \n",
              "24996         0          FP  \n",
              "24997         0          FP  \n",
              "24998         1          TP  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b04fb6a-393b-4687-8419-f0aea4c58c7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Conf_Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24989</th>\n",
              "      <td>it has been said that deanna durbin invented t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24990</th>\n",
              "      <td>meatball machine has got to be one of the most...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>TN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24991</th>\n",
              "      <td>this will be a different kind of review i've s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24992</th>\n",
              "      <td>this is a refreshing enjoyable movie if you en...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24993</th>\n",
              "      <td>this movie is a must for all people that enjoy...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24994</th>\n",
              "      <td>okay this film probably deserves 7 out of 10 s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>this is one of the most overlooked gems hollyw...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>not sure why this movie seems to have gotten s...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>FP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>good lord whoever made this turkey needs to be...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>FP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>skip mccoy richard widmark pick pockets candy'...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>TP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b04fb6a-393b-4687-8419-f0aea4c58c7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b04fb6a-393b-4687-8419-f0aea4c58c7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b04fb6a-393b-4687-8419-f0aea4c58c7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jwG7T-m8kcZ",
        "outputId": "02937c6b-b0c6-40c6-b6c6-068483acf6bb"
      },
      "source": [
        "conf_vals = imdb_slice.Conf_Matrix.value_counts().to_dict()\n",
        "print(conf_vals)\n",
        "\n",
        "accuracy = (conf_vals['TP'] + conf_vals['TN']) / (conf_vals['TP'] + conf_vals['TN'] + conf_vals['FP'] + conf_vals['FN'])\n",
        "precision = conf_vals['TP'] / (conf_vals['TP'] + conf_vals['FP'])\n",
        "recall = conf_vals['TP'] / (conf_vals['TP'] + conf_vals['FN'])\n",
        "f1_score = 2*precision*recall / (precision + recall)\n",
        "print('Accuracy: ', round(100 * accuracy, 2),'%',\n",
        "      '\\nPrecision: ', round(100 * precision, 2),'%',\n",
        "      '\\nRecall: ', round(100 * recall, 2),'%',\n",
        "      '\\nF1 Score: ', round(100 * f1_score, 2),'%')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TP': 10639, 'TN': 6744, 'FP': 5755, 'FN': 1861}\n",
            "Accuracy:  69.53 % \n",
            "Precision:  64.9 % \n",
            "Recall:  85.11 % \n",
            "F1 Score:  73.64 %\n"
          ]
        }
      ]
    }
  ]
}